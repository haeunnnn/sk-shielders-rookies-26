
<br/>

**date** : 2025-06-17 <br/>
**title** : 생성형AI 활용을 위한 머신러닝/딥러닝 2<br/>
**tags** : [데이터 전처리, 데이터 변환, 스케일링 ] <br/>

<br/>

## 📌 오늘의 키워드

- 데이터 전처리 - 데이터 전처리의 중요성, 데이터 유형, 전처리 과정
- 데이터 변환 및 스케일링 - 로그 변환/스퀘어 루트 변환, 표준화/정규화, 레이블 인코딩, 원-핫 인코딩

<br/>

## 🧠 주요 개념 정리

### 1. 데이터 전처리란
- **정의**: 데이터를 분석하거나 머신러닝 모델에 사용하기 전, 깨끗하고 유용한 상태로 준비하는 과정.
- **목적**: 비어 있는 값, 오류, 중복 등을 정리하여 분석/모델링의 정확도를 높이기 위해 필요함.

#### 데이터 전처리의 중요성
- 데이터 품질 향상 → 분석 결과의 신뢰성 확보
- 잘못된 데이터는 잘못된 결과 초래 → 시간·비용 낭비
- 단순한 작업이 아닌, 데이터 프로젝트의 핵심 단계

#### 데이터의 유형

| 유형 | 설명 | 예시 | 특징 |
| ----- | ----- | ----- | ----- |
| 정형 데이터 | 행과 열로 구성된 구조화된 데이터 | 엑셀, 데이터베이스 | 각 열에 필드명과 데이터형이 명확함 |
| 비정형 데이터 | 구조 없이 자유로운 형태의 데이터 | 이미지, 영상, 텍스트 | 가공 전엔 분석이 어려움 |
| 반정형 데이터 | 구조는 있으나 완전히 정형적이지 않은 데이터 | JSON, XML | 유연한 구조. 사람이 읽고 컴퓨터도 처리 가능 |

### 2. 데이터 전처리 과정
1. 데이터 수집
2. 데이터 정제 (Cleaning)
3. 데이터 변환 (Transformation)
4. 데이터 통합 (Integration)

#### 1. 데이터 수집
- 출처: DB(SQL/NoSQL), API, 웹 크롤링, 센서(IoT)
- 수집된 데이터는 오류/결측이 많아 품질 확인 필요

#### 2. 데이터 정제 (Cleaning)

| 작업 종류  | 설명 및 예시 |
| --------- | ---------- |
| 결측값 처리 | 평균/중간값 대체, 행/열 제거 등 |
| 오류 수정  | 오타, 음수 나이 등 |
| 중복 제거  | 동일 고객 정보 중복 행 제거 |
| 이상치 제거 | 지나치게 큰 가격 등 |

**결측치 처리**

| 방법 | 사용 상황 | 설명 |
| ---- | ------- | ----- |
| 제거 | 결측치 비율이 적을 때 | 행/열 제거 |
| 고정값 대체 | 값의 손실을 줄이고 싶을 때 | 0, 평균 등으로 대체 |
| 통계 기반 | 수치형/범주형 데이터에 활용 | 평균/중간값/최빈값 |
| 예측 기반 | 복잡한 데이터셋에서 | 머신러닝 모델로 예측 |

**이상치 처리**

| 방법 | 설명 | 적합한 경우 |
| ----- | ----- | ------- |
| IQR 방식 | 사분위 범위 기반 | 비대칭 분포 데이터 |
| Z-Score 방식 | 표준편차 기준 | 정규 분포 데이터  |

**IQR 기준**
- **이상치 하한**: Q1 - 1.5 * IQR
- **이상치 상한**: Q3 + 1.5 * IQR

**Z-Score 기준**
- 일반적으로 |Z| > 3 (또는 2) → 이상치 간주

#### 3. 데이터 변환 (Transformation)

| 작업 종류 | 설명 |
| ----- | ----- |
| 형태 변환 | 텍스트 → 숫자 (예: 성별 인코딩) |
| 정규화 | 값의 범위 조정 (예: 0\~1 스케일링) |
| 집계 | 일별 데이터를 월별로 요약 |
| 차원 축소 | 불필요한 열 제거 등 |

#### 4. 데이터 통합 (Integration)

- **목적**: 여러 출처의 데이터 통합
- **주의**: 의미·구조를 잘 이해하고 병합해야 함

| 작업 종류 | 설명 |
| -------- | ----- |
| 병합 | 여러 테이블을 키 기준으로 합치기 |
| 일관성 유지 | 포맷 맞추기 (예: 날짜 형식)  |
| 중복 제거 | 병합 중 생긴 중복 데이터 삭제  |

**데이터 중복 처리**
- **완전 중복**: 모든 열 값이 동일한 경우
**- 부분 중복**: 특정 열 값이 동일한 경우
- 중복은 분석 왜곡 및 메모리 낭비로 이어지므로 제거 필요

### 3. 데이터 변환 및 스케일링

#### 데이터 변환 (Transformation)
- **정의**: 데이터 분포를 바꿔서 분석/모델링에 적합하게 만드는 과정
- **목적**: 왜도(Skewness)를 줄이고 정규 분포에 가깝게 하여 분석 효율 향상

| 방법 | 설명 |
| ----- | ---- |
| 로그 변환 (Log) | 값의 크기 차이가 클 때 사용. 큰 값은 축소되고 작은 값은 강조되어 분포가 평탄해짐 |
| 스퀘어 루트 변환 | 덜 극단적인 변환. 오른쪽 치우침(positive skew)을 완화하는 데 유용 |

#### 비교 정리
- 로그 변환: 극단적으로 큰 값을 다룰 때 적합
- 스퀘어 루트 변환: 중간 정도의 왜도를 다룰 때 유용
- 두 방법 모두 모델 성능 향상과 데이터 해석 용이성에 도움

#### 데이터 스케일링 (Scaling)
- 정의: 변수 값의 범위를 조정하여 모델 성능 향상 및 학습 안정성 확보
- 필요성: 변수 간 단위나 크기 차이가 모델에 부정적 영향을 줄 수 있음

**표준화 (Standardization)**
| 항목 | 내용 |
| ---- | ------ |
| 정의   | 평균이 0, 표준편차가 1이 되도록 값 변환 |
| 수식   | 𝑧 = (𝑥 - 𝜇) / 𝜎 |
| 특징   | 분포의 모양은 유지되나 단위 차이 제거 |
| 장점   | 거리 기반 알고리즘(KNN, SVM 등)에 적합 |
| 주의사항 | 왜도는 여전히 남아 있을 수 있음 |

**정규화 (Normalization)**

| 항목 | 내용 |
| ---- | ------ |
| 정의   | 값을 0과 1 사이로 조정 |
| 수식   | 𝑥' = (𝑥 - min) / (max - min) |
| 특징   | 값의 범위를 일정하게 조정 |
| 장점   | 신경망, 회귀 등 스케일 민감한 모델에 적합 |
| 주의사항 | 이상치가 클 경우 왜곡 가능 → 이상치 처리 후 적용 필요 |

**표준화 vs 정규화 비교**

| 구분 | 표준화 | 정규화 |
| ----- | -------- | ----- |
| 목적 | 평균 0, 표준편차 1 | 0\~1 사이 범위로 조정 |
| 사용 모델  | KNN, SVM 등 거리 기반 모델 | 신경망, 선형 회귀 등   |
| 이상치 영향 | 상대적으로 적음 | 큼 → 이상치 제거 필요  |
| 분포 형태  | 유지됨 | 값의 상대적 크기 유지됨  |

#### 범주형 데이터 처리
- **정의**: 숫자가 아닌 텍스트 형태로 특정 범주를 나타내는 데이터 (예: "사과", "배", "포도")
- **필요성**: 대부분의 머신러닝 모델은 숫자만 인식하기 때문에 숫자 인코딩 필요

**레이블 인코딩 (Label Encoding)**

| 항목 | 내용 |
| ----- | ----- |
| 정의 | 각 범주를 정수로 매핑 (예: "사과" → 0, "배" → 1) |
| 장점 | 간단하고 메모리 효율적 |
| 단점 | 숫자가 순서를 암시할 수 있어 오류 발생 가능 |
| 사용 시기 | **순서가 있는 범주** (예: "낮음", "보통", "높음") |

**원-핫 인코딩 (One-Hot Encoding)**

| 항목 | 내용 |
| ----- | ----- |
| 정의 | 각 범주를 이진 벡터로 표현. 범주마다 열(column)을 생성 |
| 장점 | 숫자의 순서 의미 제거. 레이블 인코딩 단점 보완 |
| 단점 | **차원 증가** (범주 수만큼 열이 생김) |
| 사용 시기 | **순서가 없는 범주** (예: "사과", "배", "포도")  |

**레이블 인코딩 vs 원-핫 인코딩 비교**

| 구분 | 레이블 인코딩 | 원-핫 인코딩 |
| ----- | ---------- | ---------- |
| 표현 방식 | 정수 | 이진 벡터 (0 또는 1) |
| 순서 인식 위험 | 있음 | 없음 |
| 메모리 사용 | 적음 | 많음 (범주 수에 비례)  |
| 적합한 경우 | 순서형 데이터 | 순서 없는 범주형 데이터  |

<br/>

## 💻 실습 내용

### 실습 주제: 공공데이터를 활용한 데이터 수집 & 분석
- 데이터 출처: (서울교통공사_지하철혼잡도정보)[https://www.data.go.kr/data/15071311/fileData.do]
- 지하철 혼잡도 정보에서 2호선 강남역의 평일 혼잡도만 추출하여 시간대 별 평균 혼잡도를 추출
- matplotlib을 활용해 막대 그래프로 시각화

<br/>

## 🐛 문제 & 해결

- [에러] error → csv 파일을 불러오는 중 한글 인코딩 문제
- [해결] utf-8이 아닌 euc-kr로 불러옴 `encoding="cp949"`

<br/>

## ❓ 궁금한 점

- 궁금한 점 1
- 궁금한 점 2

<br/>

## 🔗 참고 자료

- 참고 링크 - (공공데이터포털)[https://www.data.go.kr/index.do]

<br/>

## 🗂 관련 파일

📁 코드 : [`/project/`](../project/python/2025-06-17.ipynb) <br/>
🖼 스크린샷 : [`/screenshots/`](../screenshots/2025-06-17/26AI_정하은_2호선_강남역_평일_시간대별_혼잡도.png)
