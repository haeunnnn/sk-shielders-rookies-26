
<br/>

**date** : 2025-06-19 <br/>
**title** : 생성형AI 활용을 위한 머신러닝/딥러닝 4<br/>
**tags** : [머신러닝, 지도학습, 회귀, 선형 회귀, 성능 평가] <br/>

<br/>

## 📌 오늘의 키워드

- 머신 러닝 - 지도학습 vs. 비지도학습
- 지도학습 - 회귀 알고리즘, 선형 회귀 모델
- 손실 함수(MSE)와 성능 평가(Metrics)

<br/>

## 🧠 주요 개념 정리

### 1. 머신러닝 개요 및 지도학습 소개
#### 머신러닝(Machine Learning)
- 데이터를 기반으로 컴퓨터가 스스로 패턴을 학습하고, 미래의 결과를 예측하거나 의사결정을 내리는 기술.
- 사람이 규칙을 직접 정의하지 않고, 컴퓨터가 데이터를 통해 규칙을 학습함.

#### 머신러닝의 주요 유형
| 유형 | 설명 |
| ---- | ---- |
| 지도학습 | 입력과 정답(라벨)을 모두 제공하며 학습  |
| 비지도학습 | 입력만 제공, 정답 없이 스스로 패턴 탐색 |
| 강화학습 | 행동에 대한 보상/벌점을 통해 학습 |
| 딥러닝 | 인공 신경망 기반의 복잡한 패턴 학습 |
| 생성형 AI | 데이터를 바탕으로 새로운 콘텐츠 생성 |

#### 지도학습(Supervised Learning)
- 데이터와 정답(Label)을 함께 제공하여 학습
- "질문과 답을 모두 알려주고 학습시키는 방식"
- 분류(Classification)와 회귀(Regression)로 나뉨

#### 비지도학습(Unsupervised Learning)
- 정답 없이 데이터 자체에서 패턴을 스스로 찾아냄
- 군집화(Clustering), 차원 축소 등에 사용

#### 입력(Features)과 출력(Target)
| 용어 | 설명 |
| --- | ---- |
| Feature | 모델이 학습하는 데 사용하는 특성 값 (예: 키, 몸무게) |
| Target  | 모델이 예측해야 하는 결과 값 (예: 몸무게 예측 결과)  |

#### 지도학습 주요 알고리즘 비교
| 구분 | 회귀(Regression) | 분류(Classification) |
| --- | ---------------- | ------------------- |
| 예측값 | 연속적인 수치 | 범주 (Label) |
| 대표 알고리즘 | 선형 회귀 | 로지스틱 회귀 |
| 예시 | 집값 예측, 판매량 예측  | 스팸 이메일 분류, 동물 분류   |

### 2. 데이터 준비 및 탐색
#### 데이터 전처리
| 작업 항목  | 설명 |
| --------- | ---- |
| 결측치 처리 | 비어 있는 값 채우기 또는 삭제 |
| 이상치 처리 | 정상 범위를 벗어난 값 제거 또는 수정 |

#### 탐색적 데이터 분석(EDA)
| 작업 항목 | 설명 |
| -------- | ---- |
| 통계 요약 | 평균, 중앙값, 최대값, 최소값 등                 |
| 시각화   | 그래프/차트를 통해 데이터 이해 (matplotlib 등 활용) |

#### 학습 데이터 vs 테스트 데이터
| 구분 | 설명 |
| --- | ---- |
| 학습 데이터  | 모델 학습에 사용 |
| 테스트 데이터 | 성능 평가용. 학습에 사용되지 않음 |

**데이터 분리 이유**
- 과적합 방지
- 모델의 일반화 능력 평가

### 3. 지도학습 – 회귀 알고리즘
#### 회귀(Regression)
- 연속적인 수치 예측에 사용
- 입력과 출력 간 수학적 관계(선형/비선형)를 모델링

| 회귀 종류 | 설명 |
| -------- | --- |
| 단순 선형 회귀 | 하나의 입력 변수 사용 |
| 다중 선형 회귀 | 여러 개의 입력 변수 사용 |
| 비선형 회귀   | 비선형 관계 모델링 |

#### 선형 회귀 (Linear Regression)
- 입력과 출력의 관계를 직선($𝑦 = 𝑚𝑥 + 𝑏$)으로 표현

| 항목 | 설명 |
| --- | ---- |
| $𝑥$ | 독립 변수 (입력) |
| $𝑦$ | 종속 변수 (예측) |
| $𝑚$ | 기울기 |
| $𝑏$ | y절편 |

#### 모델 학습 과정
1. **데이터 시각화** : 관계 파악
2. **손실 함수** : MSE (예측과 실제의 오차 제곱 평균)
3. **최적화 방법** : 경사 하강법(Gradient Descent)
4. **모델 생성** : 최적의 𝑚, 𝑏를 찾아 학습
5. **예측 수행** : 학습된 모델로 새로운 데이터 예측

#### 성능 평가 지표
| 지표 | 설명 | 특징 |
| ---- | ---- | ---- |
| MSE  | 평균 제곱 오차 | 큰 오차에 민감, 학습 오차 감소에 효과적
| RMSE | MSE의 제곱근 | 해석 용이, 실제 값 단위와 동일 |
| MAE  | 평균 절대 오차 | 평균 오차 직접 측정, 이상치에 강함 |
| R²   | 결정 계수. 0\~1 범위 | 모델 설명력 비율. 1에 가까울수록 좋음 |

#### Scikit-learn을 활용한 회귀
| 단계 | 설명 |
| ----- | ---- |
| 데이터 준비 | reshape 등으로 2차원 배열 준비 |
| 모델 학습  | `LinearRegression().fit()` 사용 |
| 예측 | `.predict()`로 새로운 데이터 예측 |
| 평가 | `mean_squared_error`, `r2_score` 등 활용 |

#### 과적합 vs 과소적합
| 구분 | 설명 | 해결 방법 | 
| ---- | ----- | ------- |
| 과소적합 | 너무 단순한 모델 → 학습 부족 | 더 복잡한 모델 사용, 데이터 추가 |
| 과적합  | 너무 복잡한 모델 → 학습 데이터에 과하게 적합 | 단순한 모델 사용, 정규화, 교차 검증 등 적용 |

| 규제 기법 | 설명 |
| -------- | ---- |
| L1 규제 | 중요하지 않은 특성을 제거 |
| L2 규제 | 가중치 크기를 줄여 과적합 방지 |

<br/>

## ❓ 궁금한 점

- 궁금한 점 1
- 궁금한 점 2

<br/>

## 🔗 참고 자료

- 참고 링크

<br/>

## 🗂 관련 파일

📁 코드 : [`/project/`](../project/python/2025-06-19.ipynb) <br/>
