{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b1dfd74",
   "metadata": {},
   "source": [
    "### 데이터 전처리 EX-1\n",
    "\n",
    "#### 문제 1: 결측치 처리\n",
    "- Kaggle의 [\"Titanic - Machine Learning from Disaster\"](https://www.kaggle.com/competitions/titanic) 데이터셋을 사용하여 결측치를 처리하세요.\n",
    "- 데이터셋을 불러온 후, 다음과 같이 결측치를 처리하세요.\n",
    "- Age 열의 결측치는 평균값으로 대체합니다.\n",
    "    - Embarked 열의 결측치는 최빈값(Mode)으로 대체합니다.\n",
    "    - Cabin 열은 결측치가 너무 많아서 삭제합니다.\n",
    "    - 결측치 처리 후, 결측치가 모두 제거되었는지 확인하는 코드를 작성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb90e7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ 결측치 확인 ------------\n",
      "\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "--------- 결측치 처리 후 확인 ---------\n",
      "\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 프레임 생성\n",
    "data = pd.read_csv('train.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 결측치 확인\n",
    "print(\"\\n------------ 결측치 확인 ------------\\n\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Age 열의 결측값을 평균값으로 대체\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "# Embarked 열의 결측치는 최빈값(mode)으로 대체\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "\n",
    "# Cabin 열 삭제\n",
    "df = df.drop(columns='Cabin')\n",
    "\n",
    "# 결측치 처리 확인\n",
    "print(\"\\n--------- 결측치 처리 후 확인 ---------\\n\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e457e94",
   "metadata": {},
   "source": [
    "### 데이터 전처리 EX-2\n",
    "\n",
    "#### 문제 2: 중복 데이터 제거\n",
    "임의의 데이터셋을 사용하여 중복 데이터를 제거하는 작업을 수행하세요.\n",
    "다음은 인공지능 수업에서 사용할 전처리 문제입니다.\n",
    "중복 데이터를 포함하는 생성된 파일 데이터셋을 사용하여 중복 데이터를 제거하는 작업을 수행하세요.\n",
    "\n",
    "##### 문제 요구 사항\n",
    "- sales.csv 파일을 불러옵니다. 이 파일에는 중복된 행이 일부 포함되어 있습니다.\n",
    "- 중복된 데이터의 개수를 출력하세요.\n",
    "- 중복된 행을 모두 제거한 후, 남은 데이터의 개수를 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e71b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales.csv 파일이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "#샘플 데이터 만들기\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 가짜 데이터 생성\n",
    "data = {\n",
    "    'ProductID': [101, 102, 103, 104, 101, 102, 103, 105, 106, 101],\n",
    "    'ProductName': ['A', 'B', 'C', 'D', 'A', 'B', 'C', 'E', 'F', 'A'],\n",
    "    'Price': [100, 200, 300, 400, 100, 200, 300, 500, 600, 100],\n",
    "    'Quantity': [1, 2, 3, 4, 1, 2, 3, 5, 6, 1]\n",
    "}\n",
    "\n",
    "# 2. DataFrame 생성\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 3. 중복된 데이터를 일부 추가 (중복된 행 4개 추가)\n",
    "df.loc[len(df.index)] = [101, 'A', 100, 1]  # 중복 행 추가\n",
    "df.loc[len(df.index)] = [102, 'B', 200, 2]  # 중복 행 추가\n",
    "df.loc[len(df.index)] = [103, 'C', 300, 3]  # 중복 행 추가\n",
    "df.loc[len(df.index)] = [104, 'D', 400, 4]  # 중복 행 추가\n",
    "\n",
    "# 4. CSV 파일로 내보내기\n",
    "df.to_csv('sales.csv', index=False)\n",
    "\n",
    "print(\"sales.csv 파일이 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dfd6171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ 중복된 행 확인 ------------\n",
      "\n",
      "    ProductID ProductName  Price  Quantity\n",
      "0         101           A    100         1\n",
      "1         102           B    200         2\n",
      "2         103           C    300         3\n",
      "3         104           D    400         4\n",
      "4         101           A    100         1\n",
      "5         102           B    200         2\n",
      "6         103           C    300         3\n",
      "7         105           E    500         5\n",
      "8         106           F    600         6\n",
      "9         101           A    100         1\n",
      "10        101           A    100         1\n",
      "11        102           B    200         2\n",
      "12        103           C    300         3\n",
      "13        104           D    400         4\n",
      "\n",
      "중복된 데이터의 개수: 8\n",
      "\n",
      "중복 제거 후 남은 데이터의 개수: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 프레임 생성\n",
    "df = pd.read_csv('sales.csv')\n",
    "\n",
    "# 중복된 행 확인\n",
    "print(\"\\n------------ 중복된 행 확인 ------------\\n\")\n",
    "print(df)\n",
    "\n",
    "# 중복된 데이터의 개수 출력\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"\\n중복된 데이터의 개수: {duplicate_count}\\n\")\n",
    "\n",
    "# 중복된 행을 제거\n",
    "df_no_duplicates_by_ProductID = df.drop_duplicates(subset=['ProductID'], keep='first')\n",
    "\n",
    "# 남은 데이터의 개수를 확인\n",
    "df_no_duplicates_by_ProductID_count = df_no_duplicates_by_ProductID.shape[0]\n",
    "print(f\"중복 제거 후 남은 데이터의 개수: {df_no_duplicates_by_ProductID_count}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7547dc",
   "metadata": {},
   "source": [
    "### 데이터 전처리 EX-3\n",
    "\n",
    "#### 문제 3: 이상치 제거 (IQR 이용)\n",
    "- Kaggle의 [\"Diamonds\"](https://www.kaggle.com/datasets/shivam2503/diamonds) 데이터셋을 사용하여 이상치 제거 문제를 해결하세요.\n",
    "- 이 데이터셋은 다이아몬드의 가격과 관련된 다양한 특징(캐럿, 컷, 색상, 투명도 등)을 포함하고 있습니다.\n",
    "- carat 열에서 IQR 방식을 사용하여 이상치를 제거하세요.\n",
    "- 이상치를 제거한 후 데이터의 개수를 출력하세요.\n",
    "- 이상치의 경계를 계산하여 하한(lower bound)과 상한(upper bound) 값을 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de491fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "이상치 제거 전 데이터 개수: 53940\n",
      "\n",
      "\n",
      "------------ 이상치 확인 ------------\n",
      "\n",
      "       Unnamed: 0  carat      cut color clarity  depth  table  price     x  \\\n",
      "12246       12247   2.06  Premium     J      I1   61.2   58.0   5203  8.10   \n",
      "13002       13003   2.14     Fair     J      I1   69.4   57.0   5405  7.74   \n",
      "13118       13119   2.15     Fair     J      I1   65.5   57.0   5430  8.01   \n",
      "13757       13758   2.22     Fair     J      I1   66.7   56.0   5607  8.04   \n",
      "13991       13992   2.01     Fair     I      I1   67.4   58.0   5696  7.71   \n",
      "\n",
      "          y     z  \n",
      "12246  8.07  4.95  \n",
      "13002  7.70  5.36  \n",
      "13118  7.95  5.23  \n",
      "13757  8.02  5.36  \n",
      "13991  7.64  5.17  \n",
      "\n",
      "이상치 제거 후 데이터 개수: 52051\n",
      "\n",
      "하한치: -0.5599999999999999, 상한치: 2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 프레임 생성\n",
    "data = pd.read_csv('diamonds.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 이상치 제거 전 데이터 개수 확인\n",
    "print(f\"\\n이상치 제거 전 데이터 개수: {df.shape[0]}\\n\")\n",
    "\n",
    "# IQR을 이용한 이상치 제거\n",
    "Q1 = df['carat'].quantile(0.25)\n",
    "Q3 = df['carat'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# 이상치 기준\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# 이상치 확인\n",
    "outliers = df[(df['carat'] < lower_bound) | (df['carat'] > upper_bound)]\n",
    "print(\"\\n------------ 이상치 확인 ------------\\n\")\n",
    "print(outliers.head())\n",
    "\n",
    "# 이상치 제거\n",
    "df_no_outliers = df[(df['carat'] >= lower_bound) & (df['carat'] <= upper_bound)]\n",
    "\n",
    "# 이상치 제거 후 데이터 개수 확인\n",
    "print(f\"\\n이상치 제거 후 데이터 개수: {df_no_outliers.shape[0]}\\n\")\n",
    "\n",
    "# 하한치와 상한치 출력\n",
    "print(f\"하한치: {lower_bound}, 상한치: {upper_bound}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e3679f",
   "metadata": {},
   "source": [
    "### 데이터 전처리 EX-4\n",
    "\n",
    "#### 문제 4: 범주형 데이터 인코딩\n",
    "- Kaggle의 [\"Adult Income\"](https://www.kaggle.com/wenruliu/adult-income-dataset) 데이터셋을 사용하여 범주형 데이터를 인코딩하세요.\n",
    "- workclass, education, marital-status, occupation, relationship, race, gender, native-country 열을 Label Encoding으로 변환하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8bbafd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ 레이블 인코딩 결과 ------------\n",
      "\n",
      "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
      "0   25          4  226802          1                7               4   \n",
      "1   38          4   89814         11                9               2   \n",
      "2   28          2  336951          7               12               2   \n",
      "3   44          4  160323         15               10               2   \n",
      "4   18          0  103497         15               10               4   \n",
      "\n",
      "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
      "0           7             3     2       1             0             0   \n",
      "1           5             0     4       1             0             0   \n",
      "2          11             0     4       1             0             0   \n",
      "3           7             0     2       1          7688             0   \n",
      "4           0             3     4       0             0             0   \n",
      "\n",
      "   hours-per-week  native-country income  \n",
      "0              40              39  <=50K  \n",
      "1              50              39  <=50K  \n",
      "2              40              39   >50K  \n",
      "3              40              39   >50K  \n",
      "4              30              39  <=50K  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 데이터 프레임 생성\n",
    "data = pd.read_csv('adult.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 레이블 인코딩을 위한 LabelEncoder 객체 생성\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# 범주형 데이터를 갖는 열 지정\n",
    "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']\n",
    "\n",
    "# 각 범주형 열에 대해 레이블 인코딩 수행\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# 인코딩된 데이터 확인\n",
    "print(\"\\n------------ 레이블 인코딩 결과 ------------\\n\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d3e63e",
   "metadata": {},
   "source": [
    "### 데이터 전처리 EX-5\n",
    "\n",
    "#### 문제 5: 데이터 스케일링\n",
    "- Kaggle의 [\"Wine Quality\"](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009) 데이터셋을 사용하여 데이터를 스케일링하세요.\n",
    "- fixed acidity, volatile acidity, citric acid, residual sugar, chlorides 열의 값을 StandardScaler로 표준화하세요.\n",
    "- 표준화된 결과를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e21d3f4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'winequality-red.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 데이터 프레임 생성\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwinequality-red.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m df = pd.DataFrame(data)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 표준화를 위한 스케일러 객체 생성\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ez\\Desktop\\sk-shielders-rookies-26\\project\\python\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ez\\Desktop\\sk-shielders-rookies-26\\project\\python\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ez\\Desktop\\sk-shielders-rookies-26\\project\\python\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ez\\Desktop\\sk-shielders-rookies-26\\project\\python\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ez\\Desktop\\sk-shielders-rookies-26\\project\\python\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'winequality-red.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 프레임 생성\n",
    "data = pd.read_csv('winequality-red.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 표준화를 위한 스케일러 객체 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 표준화할 열 지정\n",
    "columns_to_standardize =  ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides']\n",
    "\n",
    "# 각 열에 대해 표준화 수행\n",
    "df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n",
    "\n",
    "# 표준화된 데이터 확인\n",
    "print(\"\\n------------ 표준화된 데이터 ------------\\n\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
